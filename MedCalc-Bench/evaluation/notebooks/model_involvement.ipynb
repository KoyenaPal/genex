{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6881b8d4-ee56-4460-a318-d86d65a221f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoT Creator Involvement in Target Consistency Analysis\n",
      "Folder: ../outputs\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from matplotlib.patches import Patch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'DejaVu Serif'],\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'legend.fontsize': 11,\n",
    "    'figure.dpi': 300\n",
    "})\n",
    "\n",
    "THOUGHT_TYPES = ['Transfer', 'Ensemble']\n",
    "COLORS = {'Transfer': '#A8DADC', 'Ensemble': '#B8A9C9'}\n",
    "\n",
    "def parse_jsonl(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            return [json.loads(line) for line in f if line.strip()]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def extract_file_info(filename):\n",
    "    answer_type = 'without_answer' if 'without_answer' in filename else 'full_text'\n",
    "    \n",
    "    # Transfer CoT\n",
    "    if '_thoughts_to_' in filename:\n",
    "        match = re.match(r'(.+)_thoughts_to_(.+)_zero_shot', filename)\n",
    "        if match:\n",
    "            source_model = match.group(1)\n",
    "            target_model = match.group(2)\n",
    "            return 'Transfer', [source_model], target_model, answer_type\n",
    "    \n",
    "    # Ensemble CoT\n",
    "    elif '_gen_' in filename and '_eval_' in filename:\n",
    "        gen_match = re.search(r'_gen_(.+)_eval', filename)\n",
    "        eval_match = re.search(r'_eval_(.+?)\\.json', filename)\n",
    "        target_match = re.match(r'^(.+?)_zero_shot_ensembled', filename)\n",
    "        \n",
    "        if gen_match and eval_match and target_match:\n",
    "            gen_part = gen_match.group(1)\n",
    "            eval_model = eval_match.group(1)\n",
    "            target_model = target_match.group(1)\n",
    "            \n",
    "            # Map short names to full model names\n",
    "            short_to_full = {\n",
    "                'qwq': 'Qwen_QwQ-32B',\n",
    "                'dapo': 'BytedTsinghua-SIA_DAPO-Qwen-32B',\n",
    "                'oss': 'openai_gpt-oss-20b',\n",
    "                'opent': 'open-thoughts_OpenThinker-7B',\n",
    "                'nrr': 'nvidia_Nemotron-Research-Reasoning-Qwen-1.5B'\n",
    "            }\n",
    "            \n",
    "            # Parse generator models\n",
    "            gen_models = [short_to_full.get(model, model) for model in gen_part.split('_')]\n",
    "            full_eval_model = short_to_full.get(eval_model, eval_model)\n",
    "            \n",
    "            # Combine and deduplicate source models\n",
    "            all_sources = gen_models + [full_eval_model]\n",
    "            source_models = sorted(list(set(all_sources)))\n",
    "            \n",
    "            return 'Ensemble', source_models, target_model, answer_type\n",
    "    \n",
    "    return None, None, None, None\n",
    "\n",
    "def check_consistency(dp1, dp2, is_thoughts_to):\n",
    "    fields = (\"Target Answer\", \"Target Result\") if is_thoughts_to else (\"LLM Answer\", \"Result\")\n",
    "    \n",
    "    # Check if required fields exist\n",
    "    if fields[0] not in dp1 or fields[1] not in dp1 or fields[0] not in dp2 or fields[1] not in dp2:\n",
    "        return 0  # Missing fields = not consistent\n",
    "    \n",
    "    ans1, res1 = dp1[fields[0]], dp1[fields[1]]\n",
    "    ans2, res2 = dp2[fields[0]], dp2[fields[1]]\n",
    "    \n",
    "    invalid = [\"not defined\", \"N/A\", \"does not match\", \"are not permitted\"]\n",
    "    if any(p in ans1 or p in ans2 for p in invalid):\n",
    "        return None\n",
    "    \n",
    "    return 1 if ans1 == ans2 or (res1 == \"Correct\" and res2 == \"Correct\") else 0\n",
    "\n",
    "def calculate_stats(rates):\n",
    "    if not rates:\n",
    "        return {'mean': 0, 'stderr': 0, 'count': 0}\n",
    "    return {\n",
    "        'mean': np.mean(rates),\n",
    "        'stderr': np.std(rates) / np.sqrt(len(rates)),\n",
    "        'count': len(rates)\n",
    "    }\n",
    "\n",
    "def analyze_involvement_consistency(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        return {}\n",
    "    \n",
    "    involvement_data = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    # Collect file info\n",
    "    file_info = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jsonl') and (\"thoughts_to\" in filename or \"ensemble\" in filename):\n",
    "            info = extract_file_info(filename)\n",
    "            if info[0]:  # valid thought type\n",
    "                file_info[filename] = info\n",
    "    \n",
    "    # Calculate pairwise consistencies\n",
    "    filenames = list(file_info.keys())\n",
    "    \n",
    "    for i in range(len(filenames)):\n",
    "        for j in range(i + 1, len(filenames)):\n",
    "            file1, file2 = filenames[i], filenames[j]\n",
    "            thought_type1, sources1, target1, answer_type1 = file_info[file1]\n",
    "            thought_type2, sources2, target2, answer_type2 = file_info[file2]\n",
    "            \n",
    "            # Only compare same thought type and answer type\n",
    "            if thought_type1 != thought_type2 or answer_type1 != answer_type2:\n",
    "                continue\n",
    "            \n",
    "            # Only compare files with the same source models\n",
    "            if sources1 != sources2:\n",
    "                continue\n",
    "                \n",
    "            data1 = parse_jsonl(os.path.join(folder_path, file1))\n",
    "            data2 = parse_jsonl(os.path.join(folder_path, file2))\n",
    "            \n",
    "            if not data1 or not data2:\n",
    "                continue\n",
    "            \n",
    "            # Calculate consistency\n",
    "            consistent = total = 0\n",
    "            is_thoughts_to = '_thoughts_to_' in file1\n",
    "            \n",
    "            for dp1, dp2 in zip(data1, data2):\n",
    "                result = check_consistency(dp1, dp2, is_thoughts_to)\n",
    "                if result is not None:\n",
    "                    total += 1\n",
    "                    consistent += result\n",
    "            \n",
    "            if total > 0:\n",
    "                consistency_rate = consistent / total\n",
    "                \n",
    "                # Check if any target model helped create the CoT\n",
    "                targets_involved = (target1 in sources1 or target2 in sources1)\n",
    "                \n",
    "                involvement_data[thought_type1][answer_type1].append((targets_involved, consistency_rate))\n",
    "    \n",
    "    # Aggregate results\n",
    "    results = {}\n",
    "    for thought_type in THOUGHT_TYPES:\n",
    "        if thought_type not in involvement_data:\n",
    "            continue\n",
    "            \n",
    "        results[thought_type] = {}\n",
    "        for answer_type in ['full_text', 'without_answer']:\n",
    "            if answer_type not in involvement_data[thought_type]:\n",
    "                continue\n",
    "                \n",
    "            data = involvement_data[thought_type][answer_type]\n",
    "            involved_rates = [rate for involved, rate in data if involved]\n",
    "            not_involved_rates = [rate for involved, rate in data if not involved]\n",
    "            \n",
    "            if involved_rates or not_involved_rates:\n",
    "                results[thought_type][answer_type] = {\n",
    "                    'involved': calculate_stats(involved_rates),\n",
    "                    'not_involved': calculate_stats(not_involved_rates)\n",
    "                }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_results(results):\n",
    "    if not results:\n",
    "        print(\"No results to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    answer_types = ['full_text', 'without_answer']\n",
    "    titles = ['Full Text Conditions', 'Without Answer Conditions']\n",
    "    \n",
    "    for idx, (ax, answer_type, title) in enumerate(zip([ax1, ax2], answer_types, titles)):\n",
    "        thought_types = [t for t in THOUGHT_TYPES if t in results and answer_type in results[t]]\n",
    "        \n",
    "        if not thought_types:\n",
    "            ax.text(0.5, 0.5, 'No data available', ha='center', va='center', \n",
    "                   transform=ax.transAxes, fontsize=12)\n",
    "            ax.set_title(title, fontweight='bold', fontsize=14)\n",
    "            continue\n",
    "        \n",
    "        x = np.arange(len(thought_types))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Extract data\n",
    "        involved_means = [results[t][answer_type]['involved']['mean'] for t in thought_types]\n",
    "        involved_stderrs = [results[t][answer_type]['involved']['stderr'] for t in thought_types]\n",
    "        not_involved_means = [results[t][answer_type]['not_involved']['mean'] for t in thought_types]\n",
    "        not_involved_stderrs = [results[t][answer_type]['not_involved']['stderr'] for t in thought_types]\n",
    "        \n",
    "        colors = [COLORS[t] for t in thought_types]\n",
    "        light_colors = [f'#{int(c[1:3], 16)//2 + 127:02x}{int(c[3:5], 16)//2 + 127:02x}{int(c[5:7], 16)//2 + 127:02x}' \n",
    "                       for c in colors]\n",
    "        \n",
    "        ax.bar(x - width/2, involved_means, width, yerr=involved_stderrs,\n",
    "               color=colors, capsize=4, edgecolor='black', linewidth=0.8,\n",
    "               label='CoT Creator Involved' if idx == 0 else \"\")\n",
    "        \n",
    "        ax.bar(x + width/2, not_involved_means, width, yerr=not_involved_stderrs,\n",
    "               color=light_colors, capsize=4, edgecolor='black', linewidth=0.8, hatch='///',\n",
    "               label='CoT Creator Not Involved' if idx == 0 else \"\")\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_xlabel('Thought Type', fontweight='bold', fontsize=12)\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel('Average Pairwise Target Consistency Rate', fontweight='bold', fontsize=12)\n",
    "        ax.set_title(title, fontweight='bold', fontsize=14)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(thought_types, fontsize=11)\n",
    "        ax.grid(axis='y', linestyle='--', color='lightgray', linewidth=0.5)\n",
    "        ax.set_ylim(0, 1.0)\n",
    "        \n",
    "        for spine in ['top', 'right']:\n",
    "            ax.spines[spine].set_visible(False)\n",
    "        for spine in ['left', 'bottom']:\n",
    "            ax.spines[spine].set_linewidth(1.2)\n",
    "        \n",
    "        # Add value labels\n",
    "        all_bars = ax.patches\n",
    "        all_means = involved_means + not_involved_means\n",
    "        for bar, mean in zip(all_bars, all_means):\n",
    "            if mean > 0:\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                       f'{mean:.2f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Legend\n",
    "    handles = [\n",
    "        Patch(color='gray', edgecolor='black', linewidth=0.8, label='CoT Creator Involved'),\n",
    "        Patch(facecolor='lightgray', edgecolor='black', linewidth=0.8, hatch='///', \n",
    "              label='CoT Creator Not Involved')\n",
    "    ]\n",
    "    \n",
    "    fig.legend(handles=handles, loc='lower center', ncol=2, frameon=True, \n",
    "               fancybox=True, shadow=True, fontsize=12, bbox_to_anchor=(0.5, -0.05))\n",
    "    \n",
    "    plt.suptitle('CoT Creator Involvement in Pairwise Target Consistency', \n",
    "                fontweight='bold', fontsize=16, y=0.95)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15, top=0.85)\n",
    "    plt.savefig('cot_creator_involvement_consistency.pdf', bbox_inches='tight', \n",
    "                facecolor='white', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def print_summary(results):\n",
    "    print(\"\\nCoT CREATOR INVOLVEMENT ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for thought_type in THOUGHT_TYPES:\n",
    "        if thought_type not in results:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{thought_type.upper()}:\")\n",
    "        \n",
    "        for answer_type in ['full_text', 'without_answer']:\n",
    "            if answer_type not in results[thought_type]:\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\n  {answer_type.replace('_', ' ').title()}:\")\n",
    "            data = results[thought_type][answer_type]\n",
    "            \n",
    "            involved = data['involved']\n",
    "            not_involved = data['not_involved']\n",
    "            \n",
    "            print(f\"    Creator Involved:     {involved['mean']:.3f} ± {involved['stderr']:.3f} (n={involved['count']})\")\n",
    "            print(f\"    Creator Not Involved: {not_involved['mean']:.3f} ± {not_involved['stderr']:.3f} (n={not_involved['count']})\")\n",
    "            \n",
    "            if involved['count'] > 0 and not_involved['count'] > 0:\n",
    "                diff = involved['mean'] - not_involved['mean']\n",
    "                print(f\"    Difference:           {diff:+.3f}\")\n",
    "\n",
    "def main(folder_path):\n",
    "    print(\"CoT Creator Involvement in Target Consistency Analysis\")\n",
    "    print(f\"Folder: {folder_path}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    results = analyze_involvement_consistency(folder_path)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No valid comparisons found.\")\n",
    "        return\n",
    "    \n",
    "    plot_results(results)\n",
    "    print_summary(results)\n",
    "    print(\"Analysis complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"../outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3282ced7-9fdd-4cb0-b163-acee1fe8576d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
