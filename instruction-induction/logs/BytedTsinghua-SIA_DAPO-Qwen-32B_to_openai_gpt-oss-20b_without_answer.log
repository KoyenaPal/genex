EXECUTION ENGINE openai_gpt-oss-20b
SOURCE MODEL without_answer_dapo
OUT DIRECTORY predictions_without_answer_dapo_thoughts_to_openai_gpt-oss-20b
CAME TO THE FUNCTION TO EXECUTE ACCURACY
MXFP4 quantization requires triton >= 3.4.0 and kernels installed, we will default to dequantizing the model to bf16
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.37s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.27s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.15s/it]
CAME TO SOURCE FOLDER
  0%|          | 0/5 [00:00<?, ?it/s]user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Sentence 1: The air conditioner broke. Sentence 2: The family went to the beach.
Output: The air conditioner broke.

Input: Sentence 1: The man sued. Sentence 2: The floor was wet.
Output: The floor was wet.

Input: Sentence 1: A bird hit the engine. Sentence 2: The pilot turned on the "fasten seatbelts" light.
Output: A bird hit the engine.

Input: Sentence 1: The company's stock went up. Sentence 2: The company's posted strong earnings.
Output: The company's posted strong earnings.

Input: Sentence 1: The man turned down the music volume. Sentence 2: The man couldn't hear what the woman was saying.
Output: The man couldn't hear what the woman was saying.

The instruction was
The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
 20%|██        | 1/5 [00:02<00:10,  2.64s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Sentence 1: The meat spoiled. Sentence 2: The power was out for days.
Output: The power was out for days.

Input: Sentence 1: The woman who was walking on the street opened her umbrella. Sentence 2: It started raining.
Output: It started raining.

Input: Sentence 1: Jill won the lawsuit against Acme. Sentence 2: Acme paid Jill's legal fees.
Output: Jill won the lawsuit against Acme.

Input: Sentence 1: The company's posted strong earnings. Sentence 2: The company's stock went up.
Output: The company's posted strong earnings.

Input: Sentence 1: The man went to jail. Sentence 2: The man robbed a gas station.
Output: The man robbed a gas station.

The instruction was
 40%|████      | 2/5 [00:03<00:05,  1.75s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Sentence 1: I flipped the switch. Sentence 2: Light filled the room.
Output: I flipped the switch.

Input: Sentence 1: The man went to jail. Sentence 2: The man robbed a gas station.
Output: The man robbed a gas station.

Input: Sentence 1: The laptop ran out of battery. Sentence 2: George plugged the laptop charger in.
Output: The laptop ran out of battery.

Input: Sentence 1: Jill won the lawsuit against Acme. Sentence 2: Acme paid Jill's legal fees.
Output: Jill won the lawsuit against Acme.

Input: Sentence 1: The gardener planted a seed. Sentence 2: A flower grew.
Output: The gardener planted a seed.

The instruction was
 60%|██████    | 3/5 [00:05<00:03,  1.73s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Sentence 1: My friend celebrated with their family. Sentence 2: My friend got a promotion.
Output: My friend got a promotion.

Input: Sentence 1: The dinosaurs became extinct. Sentence 2: A large object hit the Earth.
Output: A large object hit the Earth.

Input: Sentence 1: The curtains were opened. Sentence 2: Sunlight filled the room.
Output: The curtains were opened.

Input: Sentence 1: The soda went flat. Sentence 2: The bottle was left open.
Output: The bottle was left open.

Input: Sentence 1: Jimmy took the last piece of cake. Sentence 2: Mom rinsed the tray.
Output: Jimmy took the last piece of cake.

The instruction was
 80%|████████  | 4/5 [00:07<00:01,  1.73s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Sentence 1: Mom rinsed the tray. Sentence 2: Jimmy took the last piece of cake.
Output: Jimmy took the last piece of cake.

Input: Sentence 1: A watermelon exploded. Sentence 2: A man was covered in sticky red goo.
Output: A watermelon exploded.

Input: Sentence 1: The performer ran off the stage. Sentence 2: There was a wardrobe malfunction.
Output: There was a wardrobe malfunction.

Input: Sentence 1: The man sipped the milk and spit it out. Sentence 2: The milk was left outside the fridge over night.
Output: The milk was left outside the fridge over night.

Input: Sentence 1: The company's stock went up. Sentence 2: The company's posted strong earnings.
Output: The company's posted strong earnings.

The instruction was
100%|██████████| 5/5 [00:10<00:00,  2.15s/it]100%|██████████| 5/5 [00:10<00:00,  2.02s/it]
CAME TO ONLY 30 TOKENS
CAME TO THE FUNCTION TO EXECUTE ACCURACY
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.62s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:03<00:01,  1.55s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.37s/it]
CAME TO SOURCE FOLDER
  0%|          | 0/5 [00:00<?, ?it/s]user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: elephant, chamois
Output: elephant

Input: toy poodle, koi
Output: koi

Input: dog, horse
Output: horse

Input: chinook, crocodile
Output: crocodile

Input: jaguar, common carp
Output: jaguar

The instruction was
 20%|██        | 1/5 [00:04<00:19,  4.87s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: bull shark, labradoodle
Output: bull shark

Input: elephant, poodle
Output: elephant

Input: liger, rat
Output: liger

Input: toy poodle, poodle
Output: poodle

Input: cheetah, swallow
Output: cheetah

The instruction was
 40%|████      | 2/5 [00:09<00:14,  4.69s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: jaguar, donkey
Output: jaguar

Input: sperm whale, labradoodle
Output: sperm whale

Input: guinea pig, wildebeest
Output: wildebeest

Input: dog, elephant
Output: elephant

Input: whale shark, cockapoo
Output: whale shark

The instruction was
 60%|██████    | 3/5 [00:11<00:06,  3.30s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: chimpanzee, goldfish
Output: chimpanzee

Input: parrot, bat
Output: parrot

Input: tiger, common carp
Output: tiger

Input: spider, chinook
Output: chinook

Input: alpaca, chihuahua
Output: alpaca

The instruction was
 80%|████████  | 4/5 [00:13<00:02,  2.95s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: chamois, parrot
Output: chamois

Input: sperm whale, snail
Output: sperm whale

Input: cougar, largemouth bass
Output: cougar

Input: elk, poodle
Output: elk

Input: hummingbird, chimpanzee
Output: chimpanzee

The instruction was
100%|██████████| 5/5 [00:17<00:00,  3.22s/it]100%|██████████| 5/5 [00:17<00:00,  3.44s/it]
CAME TO ONLY 30 TOKENS
CAME TO THE FUNCTION TO EXECUTE ACCURACY
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.56s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.21s/it]
CAME TO SOURCE FOLDER
  0%|          | 0/5 [00:00<?, ?it/s]user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: 4933
Output: four thousand, nine hundred and thirty-three

Input: 3674
Output: three thousand, six hundred and seventy-four

Input: 6747
Output: six thousand, seven hundred and forty-seven

Input: 6031
Output: six thousand and thirty-one

Input: 971
Output: nine hundred and seventy-one

The instruction was
 20%|██        | 1/5 [00:02<00:10,  2.69s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: 7702
Output: seven thousand, seven hundred and two

Input: 8524
Output: eight thousand, five hundred and twenty-four

Input: 2743
Output: two thousand, seven hundred and forty-three

Input: 2401
Output: two thousand, four hundred and one

Input: 4563
Output: four thousand, five hundred and sixty-three

The instruction was
 40%|████      | 2/5 [00:05<00:09,  3.03s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: 2542
Output: two thousand, five hundred and forty-two

Input: 5879
Output: five thousand, eight hundred and seventy-nine

Input: 752
Output: seven hundred and fifty-two

Input: 2314
Output: two thousand, three hundred and fourteen

Input: 4047
Output: four thousand and forty-seven

The instruction was
 60%|██████    | 3/5 [00:08<00:05,  2.99s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: 9067
Output: nine thousand and sixty-seven

Input: 5087
Output: five thousand and eighty-seven

Input: 853
Output: eight hundred and fifty-three

Input: 1277
Output: one thousand, two hundred and seventy-seven

Input: 7520
Output: seven thousand, five hundred and twenty

The instruction was
 80%|████████  | 4/5 [00:10<00:02,  2.59s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: 3826
Output: three thousand, eight hundred and twenty-six

Input: 7959
Output: seven thousand, nine hundred and fifty-nine

Input: 6507
Output: six thousand, five hundred and seven

Input: 8491
Output: eight thousand, four hundred and ninety-one

Input: 1047
Output: one thousand and forty-seven

The instruction was
100%|██████████| 5/5 [00:13<00:00,  2.50s/it]100%|██████████| 5/5 [00:13<00:00,  2.65s/it]
CAME TO ONLY 30 TOKENS
CAME TO THE FUNCTION TO EXECUTE ACCURACY
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.39s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.20s/it]
CAME TO SOURCE FOLDER
  0%|          | 0/5 [00:00<?, ?it/s]user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: You may pick any flower, but leave a few for Mary. [p]
Output: pick

Input: Ellen talked with Helen about the problem. [t]
Output: talked the

Input: The very young child walked from school to the store. [v]
Output: very

Input: He is not finishing. [h]
Output: he

Input: Dana doubts that Drew believes I think Rosie loves magazine ads. [t]
Output: that think

The instruction was
 20%|██        | 1/5 [00:03<00:15,  3.98s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Fiona must not eat the sauteed candy canes. [t]
Output: the

Input: They denied the claim that they should report only to us. [c]
Output: claim

Input: He always eats deep fried muffins. [d]
Output: deep

Input: The student was hoping for a good clue. [w]
Output: was

Input: I will eat spaghetti on Sunday with Marco. [o]
Output: on

The instruction was
 40%|████      | 2/5 [00:07<00:10,  3.46s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Gilgamesh wanted to seduce Ishtar, and seduce Ishtar he did . [g]
Output: gilgamesh

Input: Truman punched Johnson [j]
Output: johnson

Input: The scenes to which the censors took objection had to do with the mixed marriage of a woman and a giant panda. [w]
Output: which with woman

Input: John persuaded Stephen to be more careful. [m]
Output: more

Input: Susan found every book she had been looking for at Borders. [f]
Output: found for

The instruction was
 60%|██████    | 3/5 [00:09<00:05,  2.98s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: I am anxious for you to arrive on time. [t]
Output: to time

Input: Confiscate any liquor. [c]
Output: confiscate

Input: We peered around the room. [a]
Output: around

Input: Why did you kill Pegasus? [k]
Output: kill

Input: Susan found every book she had been looking for at Borders. [l]
Output: looking

The instruction was
 80%|████████  | 4/5 [00:13<00:03,  3.46s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Imogen broke the vase. [b]
Output: broke

Input: Aphrodite may quickly free the animals. [a]
Output: aphrodite animals

Input: The man on whose lap the puppet is sitting is ventriloquist. [s]
Output: sitting

Input: John believes it to be obvious that Bill left. [t]
Output: to that

Input: Julia and Maria wanted to be allowed to perform a play. [a]
Output: and allowed a

The instruction was
100%|██████████| 5/5 [00:17<00:00,  3.52s/it]100%|██████████| 5/5 [00:17<00:00,  3.46s/it]
CAME TO ONLY 30 TOKENS
CAME TO THE FUNCTION TO EXECUTE ACCURACY
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.44s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.22s/it]
CAME TO SOURCE FOLDER
  0%|          | 0/5 [00:00<?, ?it/s]user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: stand
Output: demand

Input: pig
Output: dig

Input: information
Output: reservation

Input: cheese
Output: disease

Input: stain
Output: main

The instruction was
 20%|██        | 1/5 [00:05<00:20,  5.21s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: collect
Output: connect

Input: invitation
Output: station

Input: musician
Output: composition

Input: name
Output: game

Input: cake
Output: shake

The instruction was
 40%|████      | 2/5 [00:09<00:14,  4.75s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: cave
Output: behave

Input: snow
Output: so

Input: relation
Output: station

Input: mess
Output: less

Input: sick
Output: quick

The instruction was
 60%|██████    | 3/5 [00:12<00:07,  3.92s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: make
Output: break

Input: depressed
Output: northwest

Input: suggest
Output: west

Input: see
Output: free

Input: grill
Output: spill

The instruction was
 80%|████████  | 4/5 [00:15<00:03,  3.71s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: examination
Output: celebration

Input: so
Output: toe

Input: site
Output: height

Input: shoe
Output: you

Input: situation
Output: generation

The instruction was
100%|██████████| 5/5 [00:16<00:00,  2.57s/it]100%|██████████| 5/5 [00:16<00:00,  3.30s/it]
CAME TO ONLY 30 TOKENS
CAME TO THE FUNCTION TO EXECUTE ACCURACY
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.06s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.84s/it]
Traceback (most recent call last):
  File "/instruction-induction/execute_instructions.py", line 258, in <module>
    run_execution_accuracy_open_source_chat(execution_engine=args.execution_engine,
  File "/instruction-induction/execute_instructions.py", line 80, in run_execution_accuracy_open_source_chat
    model = AutoModelForCausalLM.from_pretrained(execution_engine, dtype=torch.bfloat16, device_map="auto", cache_dir="/workspace/hf")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 288, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 5179, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 5642, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 946, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 854, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/.venv/lib/python3.11/site-packages/transformers/quantizers/quantizer_mxfp4.py", line 249, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/.venv/lib/python3.11/site-packages/transformers/integrations/mxfp4.py", line 329, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/integrations/mxfp4.py", line 117, in convert_moe_packed_tensors
    idx_hi = (blk >> 4).to(torch.long)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacity of 139.83 GiB of which 482.00 MiB is free. Process 82126 has 60.28 GiB memory in use. Process 85410 has 79.06 GiB memory in use. Of the allocated memory 76.30 GiB is allocated by PyTorch, and 2.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
