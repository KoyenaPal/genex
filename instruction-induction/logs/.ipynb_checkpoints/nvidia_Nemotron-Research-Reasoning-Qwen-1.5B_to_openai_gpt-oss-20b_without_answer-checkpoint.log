EXECUTION ENGINE openai_gpt-oss-20b
SOURCE MODEL without_answer_nrr
OUT DIRECTORY predictions_without_answer_nrr_thoughts_to_openai_gpt-oss-20b
CAME TO THE FUNCTION TO EXECUTE ACCURACY
MXFP4 quantization requires triton >= 3.4.0 and kernels installed, we will default to dequantizing the model to bf16
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.18s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.02it/s]
CAME TO SOURCE FOLDER
  0%|          | 0/5 [00:00<?, ?it/s]user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Sentence 1: The air conditioner broke. Sentence 2: The family went to the beach.
Output: The air conditioner broke.

Input: Sentence 1: The man sued. Sentence 2: The floor was wet.
Output: The floor was wet.

Input: Sentence 1: A bird hit the engine. Sentence 2: The pilot turned on the "fasten seatbelts" light.
Output: A bird hit the engine.

Input: Sentence 1: The company's stock went up. Sentence 2: The company's posted strong earnings.
Output: The company's posted strong earnings.

Input: Sentence 1: The man turned down the music volume. Sentence 2: The man couldn't hear what the woman was saying.
Output: The man couldn't hear what the woman was saying.

The instruction was
The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
 20%|██        | 1/5 [00:01<00:07,  1.92s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Sentence 1: The meat spoiled. Sentence 2: The power was out for days.
Output: The power was out for days.

Input: Sentence 1: The woman who was walking on the street opened her umbrella. Sentence 2: It started raining.
Output: It started raining.

Input: Sentence 1: Jill won the lawsuit against Acme. Sentence 2: Acme paid Jill's legal fees.
Output: Jill won the lawsuit against Acme.

Input: Sentence 1: The company's posted strong earnings. Sentence 2: The company's stock went up.
Output: The company's posted strong earnings.

Input: Sentence 1: The man went to jail. Sentence 2: The man robbed a gas station.
Output: The man robbed a gas station.

The instruction was
 40%|████      | 2/5 [00:03<00:04,  1.65s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Sentence 1: I flipped the switch. Sentence 2: Light filled the room.
Output: I flipped the switch.

Input: Sentence 1: The man went to jail. Sentence 2: The man robbed a gas station.
Output: The man robbed a gas station.

Input: Sentence 1: The laptop ran out of battery. Sentence 2: George plugged the laptop charger in.
Output: The laptop ran out of battery.

Input: Sentence 1: Jill won the lawsuit against Acme. Sentence 2: Acme paid Jill's legal fees.
Output: Jill won the lawsuit against Acme.

Input: Sentence 1: The gardener planted a seed. Sentence 2: A flower grew.
Output: The gardener planted a seed.

The instruction was
 60%|██████    | 3/5 [00:04<00:02,  1.22s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Sentence 1: My friend celebrated with their family. Sentence 2: My friend got a promotion.
Output: My friend got a promotion.

Input: Sentence 1: The dinosaurs became extinct. Sentence 2: A large object hit the Earth.
Output: A large object hit the Earth.

Input: Sentence 1: The curtains were opened. Sentence 2: Sunlight filled the room.
Output: The curtains were opened.

Input: Sentence 1: The soda went flat. Sentence 2: The bottle was left open.
Output: The bottle was left open.

Input: Sentence 1: Jimmy took the last piece of cake. Sentence 2: Mom rinsed the tray.
Output: Jimmy took the last piece of cake.

The instruction was
 80%|████████  | 4/5 [00:05<00:01,  1.29s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: Sentence 1: Mom rinsed the tray. Sentence 2: Jimmy took the last piece of cake.
Output: Jimmy took the last piece of cake.

Input: Sentence 1: A watermelon exploded. Sentence 2: A man was covered in sticky red goo.
Output: A watermelon exploded.

Input: Sentence 1: The performer ran off the stage. Sentence 2: There was a wardrobe malfunction.
Output: There was a wardrobe malfunction.

Input: Sentence 1: The man sipped the milk and spit it out. Sentence 2: The milk was left outside the fridge over night.
Output: The milk was left outside the fridge over night.

Input: Sentence 1: The company's stock went up. Sentence 2: The company's posted strong earnings.
Output: The company's posted strong earnings.

The instruction was
100%|██████████| 5/5 [00:06<00:00,  1.11s/it]100%|██████████| 5/5 [00:06<00:00,  1.26s/it]
CAME TO ONLY 30 TOKENS
CAME TO THE FUNCTION TO EXECUTE ACCURACY
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.05s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]
CAME TO SOURCE FOLDER
  0%|          | 0/5 [00:00<?, ?it/s]user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: elephant, chamois
Output: elephant

Input: toy poodle, koi
Output: koi

Input: dog, horse
Output: horse

Input: chinook, crocodile
Output: crocodile

Input: jaguar, common carp
Output: jaguar

The instruction was
 20%|██        | 1/5 [00:01<00:05,  1.41s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: bull shark, labradoodle
Output: bull shark

Input: elephant, poodle
Output: elephant

Input: liger, rat
Output: liger

Input: toy poodle, poodle
Output: poodle

Input: cheetah, swallow
Output: cheetah

The instruction was
 40%|████      | 2/5 [00:02<00:04,  1.34s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: jaguar, donkey
Output: jaguar

Input: sperm whale, labradoodle
Output: sperm whale

Input: guinea pig, wildebeest
Output: wildebeest

Input: dog, elephant
Output: elephant

Input: whale shark, cockapoo
Output: whale shark

The instruction was
 60%|██████    | 3/5 [00:04<00:02,  1.33s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: chimpanzee, goldfish
Output: chimpanzee

Input: parrot, bat
Output: parrot

Input: tiger, common carp
Output: tiger

Input: spider, chinook
Output: chinook

Input: alpaca, chihuahua
Output: alpaca

The instruction was
 80%|████████  | 4/5 [00:05<00:01,  1.34s/it]CAME TO ONLY 30 TOKENS
user_prompt I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input-output pairs:

Input: chamois, parrot
Output: chamois

Input: sperm whale, snail
Output: sperm whale

Input: cougar, largemouth bass
Output: cougar

Input: elk, poodle
Output: elk

Input: hummingbird, chimpanzee
Output: chimpanzee

The instruction was
100%|██████████| 5/5 [00:06<00:00,  1.32s/it]100%|██████████| 5/5 [00:06<00:00,  1.33s/it]
CAME TO ONLY 30 TOKENS
CAME TO THE FUNCTION TO EXECUTE ACCURACY
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.80s/it]
Traceback (most recent call last):
  File "/instruction-induction/execute_instructions.py", line 253, in <module>
    run_execution_accuracy_open_source_chat(execution_engine=args.execution_engine,
  File "/instruction-induction/execute_instructions.py", line 78, in run_execution_accuracy_open_source_chat
    model = AutoModelForCausalLM.from_pretrained(execution_engine, dtype=torch.bfloat16, device_map="auto", cache_dir="/workspace/hf")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 288, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 5179, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 5642, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 946, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 854, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/.venv/lib/python3.11/site-packages/transformers/quantizers/quantizer_mxfp4.py", line 249, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/.venv/lib/python3.11/site-packages/transformers/integrations/mxfp4.py", line 329, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/transformers/integrations/mxfp4.py", line 117, in convert_moe_packed_tensors
    idx_hi = (blk >> 4).to(torch.long)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacity of 139.83 GiB of which 1.63 GiB is free. Process 3622196 has 76.67 GiB memory in use. Process 3651729 has 23.95 GiB memory in use. Process 3674907 has 37.56 GiB memory in use. Of the allocated memory 33.81 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
